{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, seaborn as sns, numpy as np, matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer \n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_val_predict, GridSearchCV, KFold, \\\n",
    "StratifiedKFold, learning_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, r2_score\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare various classifiers accuracy and classification report with Vader sentiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just another flavor of kit kat but the taste i...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[flavor, kit, kat, taste, unique, bit, differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i bought this on impulse and it comes from jap...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[bought, impulse, japan, amused, family, weird...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really good great gift for any fan of green te...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[good, great, gift, fan, green, tea, expensive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i had never had it before was curious to see w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[curious, like, smooth, great, subtle, good, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ive been looking forward to trying these after...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[ive, looking, forward, trying, hearing, popul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  \\\n",
       "0  just another flavor of kit kat but the taste i...      4.0   \n",
       "1  i bought this on impulse and it comes from jap...      3.0   \n",
       "2  really good great gift for any fan of green te...      4.0   \n",
       "3  i had never had it before was curious to see w...      5.0   \n",
       "4  ive been looking forward to trying these after...      4.0   \n",
       "\n",
       "                                 reviewText_tokenize  \n",
       "0  [flavor, kit, kat, taste, unique, bit, differe...  \n",
       "1  [bought, impulse, japan, amused, family, weird...  \n",
       "2  [good, great, gift, fan, green, tea, expensive...  \n",
       "3  [curious, like, smooth, great, subtle, good, f...  \n",
       "4  [ive, looking, forward, trying, hearing, popul...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('amazon_food-tokenize.csv', index_col=0, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.reviewText_tokenize\n",
    "y = df.overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sm = SMOTEENN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best hyper-parameters = {'cls__alpha': 0.10000000000000001}\n",
      "best score = 0.592687741436\n",
      "\n",
      "best estimator = Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        str...use_idf=True)), ('cls', MultinomialNB(alpha=0.10000000000000001, class_prior=None, fit_prior=True))])\n",
      "\n",
      "Time taken : 1013.68899703  seconds\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - MultinomialNB - GridSearchCV\n",
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', MultinomialNB())\n",
    "]) \n",
    "\n",
    "params = dict(cls__alpha=np.linspace(0.1, 10, 10))\n",
    "grid_search = GridSearchCV(pipeline, param_grid=params, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print 'best hyper-parameters =', grid_search.best_params_\n",
    "print 'best score =', grid_search.best_score_\n",
    "print ''\n",
    "print 'best estimator =',grid_search.best_estimator_\n",
    "print ''\n",
    "\n",
    "end = time.time()\n",
    "exe_time = end - start\n",
    "print 'Time taken :',(exe_time),' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594155629504\n",
      "Time taken : 43.7946031094  seconds\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - MultinomialNB\n",
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', MultinomialNB(alpha=0.1))\n",
    "]) \n",
    "pipeline.fit(X_train, y_train)\n",
    "nb_predicted = pipeline.predict(X_test)\n",
    "print pipeline.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "exe_time = end - start\n",
    "print 'Time taken :',(exe_time),' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.90      0.01      0.02      1743\n",
      "        2.0       1.00      0.01      0.01      2341\n",
      "        3.0       0.61      0.03      0.05      5287\n",
      "        4.0       0.40      0.09      0.15      9825\n",
      "        5.0       0.60      0.99      0.75     26181\n",
      "\n",
      "avg / total       0.59      0.59      0.47     45377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, nb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper-parameters = {'cls__solver': 'newton-cg'}\n",
      "best score = 0.652634660975\n",
      "\n",
      "best estimator = Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        str...ty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "\n",
      "Time taken : 18.2112945318  minutes\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - GridSearchCV\n",
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', LogisticRegression())\n",
    "]) \n",
    "\n",
    "params = dict(cls__solver=['newton-cg', 'lbfgs', 'sag'])\n",
    "grid_search = GridSearchCV(pipeline, param_grid=params)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print 'best hyper-parameters =', grid_search.best_params_\n",
    "print 'best score =', grid_search.best_score_\n",
    "print ''\n",
    "print 'best estimator =',grid_search.best_estimator_\n",
    "print ''\n",
    "\n",
    "end = time.time()\n",
    "exe_time = (end - start)/60\n",
    "print 'Time taken :',(exe_time),' minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662295876766\n",
      "Time taken : 163.688863993  seconds\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', LogisticRegression(solver='newton-cg'))\n",
    "]) \n",
    "pipeline.fit(X_train, y_train)\n",
    "lr_predicted = pipeline.predict(X_test)\n",
    "print pipeline.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "exe_time = end - start\n",
    "print 'Time taken :',(exe_time),' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.69      0.22      0.33      1743\n",
      "        2.0       0.42      0.08      0.14      2341\n",
      "        3.0       0.47      0.30      0.37      5287\n",
      "        4.0       0.49      0.36      0.41      9825\n",
      "        5.0       0.72      0.93      0.81     26181\n",
      "\n",
      "avg / total       0.62      0.66      0.62     45377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, lr_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.596866253829\n",
      "Time taken : 860.863065004  seconds\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', RandomForestClassifier())\n",
    "]) \n",
    "pipeline.fit(X_train, y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print pipeline.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "exe_time = end - start\n",
    "print 'Time taken :',(exe_time),' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cheeyongquah/anaconda/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625316790444\n",
      "Time taken : 43.0113868713  seconds\n"
     ]
    }
   ],
   "source": [
    "# SGDClassifier\n",
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', SGDClassifier())\n",
    "]) \n",
    "pipeline.fit(X_train, y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print pipeline.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "exe_time = end - start\n",
    "print 'Time taken :',(exe_time),' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.577583357207\n",
      "Time taken : 7284.43519688  seconds\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', SVC())\n",
    "]) \n",
    "pipeline.fit(X_train, y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print pipeline.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "exe_time = end - start\n",
    "print 'Time taken :',(exe_time),' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper-parameters = {'cls__learning_rate': 0.6, 'cls__max_depth': 3}\n",
      "best score = 0.64305751013\n",
      "\n",
      "best estimator = Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error='ignore',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
      "        str...n_estimators=100, nthread=-1, objective='multi:softprob', seed=0,\n",
      "       silent=True, subsample=1))])\n",
      "\n",
      "Time taken : 271.923445217  minutes\n"
     ]
    }
   ],
   "source": [
    "# XGBoost - GridSearch\n",
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', XGBClassifier(objective='multi:softmax'))\n",
    "]) \n",
    "params = dict(cls__learning_rate=[0.2, 0.4, 0.6], cls__max_depth=[2,3,4])\n",
    "grid_search = GridSearchCV(pipeline, param_grid=params)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print 'best hyper-parameters =', grid_search.best_params_\n",
    "print 'best score =', grid_search.best_score_\n",
    "print ''\n",
    "print 'best estimator =',grid_search.best_estimator_\n",
    "print ''\n",
    "\n",
    "end = time.time()\n",
    "exe_time = (end - start)/60\n",
    "print 'Time taken :',(exe_time),' minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648852943121\n",
      "Time taken : 14.5472668171  minutes\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', XGBClassifier(learning_rate=0.6, max_depth=3, objective='multi:softmax'))\n",
    "]) \n",
    "pipeline.fit(X_train, y_train)\n",
    "xgb_predicted = pipeline.predict(X_test)\n",
    "print pipeline.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "exe_time = (end - start)/60\n",
    "print 'Time taken :',(exe_time),' minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.52      0.26      0.35      1743\n",
      "        2.0       0.37      0.13      0.19      2341\n",
      "        3.0       0.47      0.27      0.34      5287\n",
      "        4.0       0.49      0.29      0.36      9825\n",
      "        5.0       0.70      0.93      0.80     26181\n",
      "\n",
      "avg / total       0.60      0.65      0.60     45377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, xgb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline GridsearchCV \n",
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', SGDClassifier())\n",
    "]) \n",
    "\n",
    "params = dict(cls=[MultinomialNB(), SGDClassifier()],\n",
    "              cls__alpha=[0.0001, 0.001, 0.01, 0.1, 0.5, 1.0])\n",
    "grid_search = GridSearchCV(pipeline, param_grid=params)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print ''\n",
    "print 'best hyper-parameters =', grid_search.best_params_\n",
    "print 'best score =', grid_search.best_score_\n",
    "print ''\n",
    "print 'best estimator =',grid_search.best_estimator_\n",
    "\n",
    "end = time.time()\n",
    "exe_time = (end - start)/60\n",
    "print 'Time taken :',(exe_time),' minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cheeyongquah/anaconda/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635938911784\n",
      "Time taken : 31.4764133811  minutes\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Voting Classifier\n",
    "start = time.time()\n",
    "\n",
    "clf1 = LogisticRegression(solver='newton-cg')\n",
    "clf2 = RandomForestClassifier()\n",
    "clf4 = MultinomialNB(alpha=0.1)\n",
    "clf5 = SGDClassifier()\n",
    "clf6 = XGBClassifier(learning_rate=0.6, max_depth=3, objective='multi:softmax')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,2), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('mnb', clf4), ('sgd', clf5),\n",
    "                                        ('xgb', clf6)], voting='hard'))\n",
    "]) \n",
    "pipeline.fit(X_train, y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print pipeline.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "exe_time = (end - start)/60\n",
    "print 'Time taken :',(exe_time),' minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Vader sentiment analyzer with Logistic Regression\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just another flavor of kit kat but the taste i...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[flavor, kit, kat, taste, unique, bit, differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i bought this on impulse and it comes from jap...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[bought, impulse, japan, amused, family, weird...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really good great gift for any fan of green te...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[good, great, gift, fan, green, tea, expensive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i had never had it before was curious to see w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[curious, like, smooth, great, subtle, good, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ive been looking forward to trying these after...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[ive, looking, forward, trying, hearing, popul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  \\\n",
       "0  just another flavor of kit kat but the taste i...      4.0   \n",
       "1  i bought this on impulse and it comes from jap...      3.0   \n",
       "2  really good great gift for any fan of green te...      4.0   \n",
       "3  i had never had it before was curious to see w...      5.0   \n",
       "4  ive been looking forward to trying these after...      4.0   \n",
       "\n",
       "                                 reviewText_tokenize  \n",
       "0  [flavor, kit, kat, taste, unique, bit, differe...  \n",
       "1  [bought, impulse, japan, amused, family, weird...  \n",
       "2  [good, great, gift, fan, green, tea, expensive...  \n",
       "3  [curious, like, smooth, great, subtle, good, f...  \n",
       "4  [ive, looking, forward, trying, hearing, popul...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken : 19.8124195496  minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "df['vader_neg'] = 0\n",
    "df['vader_pos'] = 0\n",
    "df['vader_neu'] = 0\n",
    "df['vader_compound'] = 0\n",
    "\n",
    "for i, q in enumerate(df.reviewText_tokenize.values):\n",
    "    vs = analyzer.polarity_scores(q)\n",
    "    df.iloc[i, -4] = vs['neg']\n",
    "    df.iloc[i, -3] = vs['pos']\n",
    "    df.iloc[i, -2] = vs['neu']\n",
    "    df.iloc[i, -1] = vs['compound']\n",
    "    \n",
    "end = time.time()\n",
    "exe_time = (end - start)/60\n",
    "print 'Time taken :',(exe_time),' minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText_tokenize</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151249</th>\n",
       "      <td>delicious glutenfree oatmeal we tried both the...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[delicious, glutenfree, oatmeal, tried, regula...</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.9713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151250</th>\n",
       "      <td>with the many selections of instant oatmeal ce...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[selection, instant, oatmeal, cereal, produced...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.8271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151251</th>\n",
       "      <td>while i usually review cds and dvds as well as...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[usually, review, cd, dvd, entertainment, rela...</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.9485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151252</th>\n",
       "      <td>my son and i enjoyed these oatmeal packets  he...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[son, enjoyed, oatmeal, packet, fond, maple, b...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.9595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151253</th>\n",
       "      <td>i like to eat oatmeal i the mornings i usually...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[like, oatmeal, morning, usually, buy, quaker,...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.7024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  overall  \\\n",
       "151249  delicious glutenfree oatmeal we tried both the...      4.0   \n",
       "151250  with the many selections of instant oatmeal ce...      4.0   \n",
       "151251  while i usually review cds and dvds as well as...      5.0   \n",
       "151252  my son and i enjoyed these oatmeal packets  he...      4.0   \n",
       "151253  i like to eat oatmeal i the mornings i usually...      4.0   \n",
       "\n",
       "                                      reviewText_tokenize  vader_neg  \\\n",
       "151249  [delicious, glutenfree, oatmeal, tried, regula...      0.041   \n",
       "151250  [selection, instant, oatmeal, cereal, produced...      0.000   \n",
       "151251  [usually, review, cd, dvd, entertainment, rela...      0.037   \n",
       "151252  [son, enjoyed, oatmeal, packet, fond, maple, b...      0.000   \n",
       "151253  [like, oatmeal, morning, usually, buy, quaker,...      0.078   \n",
       "\n",
       "        vader_pos  vader_neu  vader_compound  \n",
       "151249      0.400      0.559          0.9713  \n",
       "151250      0.111      0.889          0.8271  \n",
       "151251      0.204      0.759          0.9485  \n",
       "151252      0.341      0.659          0.9595  \n",
       "151253      0.183      0.739          0.7024  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[['vader_neg','vader_pos','vader_neu','vader_compound']]\n",
    "y = df.overall.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs_train, Xs_test, y_train, y_test = train_test_split(Xs, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='newton-cg').fit(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.577429094034\n"
     ]
    }
   ],
   "source": [
    "lr_vader_predicted = lr.predict(Xs_test) \n",
    "print lr.score(Xs_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.23      0.06      0.10      1762\n",
      "        2.0       0.00      0.00      0.00      2317\n",
      "        3.0       0.21      0.00      0.00      5334\n",
      "        4.0       1.00      0.00      0.00      9703\n",
      "        5.0       0.58      0.99      0.73     26261\n",
      "\n",
      "avg / total       0.58      0.58      0.43     45377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, lr_vader_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57819059  0.5773172   0.57803048  0.57666116  0.57739355]\n",
      "0.577518595375\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), Xs, y, cv=5)\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
