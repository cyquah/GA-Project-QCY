{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.en import English\n",
    "import re\n",
    "\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Title', u'Details', u'Date', u'Details_processed', u'Word_count'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding to utf-8 here is important \n",
    "df = pd.read_csv('combined_blogs.csv', index_col=0, encoding = 'utf-8')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.drop('tokenised_with_stopwords', inplace=True, axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    # get rid of newlines\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    \n",
    "    # replace twitter @mentions\n",
    "    mentionFinder = re.compile(r\"@[a-z0-9_]{1,15}\", re.IGNORECASE)\n",
    "    text = mentionFinder.sub(\"@MENTION\", text)\n",
    "    \n",
    "    # replace HTML symbols\n",
    "    text = text.replace(\"&amp;\", \"and\").replace(\"&gt;\", \">\").replace(\"&lt;\", \"<\")\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleantext = []\n",
    "for row in df.Details_processed:\n",
    "    r = cleanText(row)\n",
    "    cleantext.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom stoplist\n",
    "STOPLIST = set(stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom function to tokenize the text using spaCy and convert to lemmas\n",
    "def tokenizeText(sample):\n",
    "\n",
    "    # get the tokens using spaCy\n",
    "    tokens = parser(sample)\n",
    "\n",
    "    # lemmatize\n",
    "    # lemmas = []\n",
    "    # for tok in tokens:\n",
    "    #    lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    # tokens = lemmas\n",
    "\n",
    "    # stoplist the tokens\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for item in cleantext:    \n",
    "    t = tokenizeText(item)\n",
    "    tokens.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tokenised_with_stopwords'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Details</th>\n",
       "      <th>Date</th>\n",
       "      <th>Details_processed</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>tokenised_with_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27 Local Breakfast in the East That’s Better T...</td>\n",
       "      <td>image  text by maureen  mu qin breakfast is th...</td>\n",
       "      <td>Jul 26th, 2016</td>\n",
       "      <td>image text by maureen mu qin breakfast is the ...</td>\n",
       "      <td>3750</td>\n",
       "      <td>[image, text, by, maureen, mu, qin, breakfast,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27 Bak Chor Mee Singaporeans Love (Which is Yo...</td>\n",
       "      <td>bak chor mee which translates to minced meat n...</td>\n",
       "      <td>Mar 3rd, 2017</td>\n",
       "      <td>bak chor mee which translates to minced meat n...</td>\n",
       "      <td>2142</td>\n",
       "      <td>[bak, chor, mee, which, translates, to, minced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19 Popular Hokkien Prawn Mee in Singapore (We ...</td>\n",
       "      <td>hokkien prawn mee is an iconic singapore dish ...</td>\n",
       "      <td>Dec 15th, 2016</td>\n",
       "      <td>hokkien prawn mee is an iconic singapore dish ...</td>\n",
       "      <td>2918</td>\n",
       "      <td>[hokkien, prawn, mee, is, an, iconic, singapor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waa Cow! Sushi Bar – Quality Wagyu Sushi Sets ...</td>\n",
       "      <td>if youre from nus youve probably treated yours...</td>\n",
       "      <td>Oct 11th, 2017</td>\n",
       "      <td>if youre from nu youve probably treated yourse...</td>\n",
       "      <td>582</td>\n",
       "      <td>[if, you, re, from, nu, you, ve, probably, tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hawkerman – Your Favourite Hawkers Under One r...</td>\n",
       "      <td>the newly opened hawkerman a soontobe halal c...</td>\n",
       "      <td>Oct 10th, 2017</td>\n",
       "      <td>the newly opened hawkerman a soontobe halal ce...</td>\n",
       "      <td>527</td>\n",
       "      <td>[the, newly, opened, hawkerman, a, soontobe, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  27 Local Breakfast in the East That’s Better T...   \n",
       "1  27 Bak Chor Mee Singaporeans Love (Which is Yo...   \n",
       "2  19 Popular Hokkien Prawn Mee in Singapore (We ...   \n",
       "3  Waa Cow! Sushi Bar – Quality Wagyu Sushi Sets ...   \n",
       "4  Hawkerman – Your Favourite Hawkers Under One r...   \n",
       "\n",
       "                                             Details            Date  \\\n",
       "0  image  text by maureen  mu qin breakfast is th...  Jul 26th, 2016   \n",
       "1  bak chor mee which translates to minced meat n...   Mar 3rd, 2017   \n",
       "2  hokkien prawn mee is an iconic singapore dish ...  Dec 15th, 2016   \n",
       "3  if youre from nus youve probably treated yours...  Oct 11th, 2017   \n",
       "4   the newly opened hawkerman a soontobe halal c...  Oct 10th, 2017   \n",
       "\n",
       "                                   Details_processed  Word_count  \\\n",
       "0  image text by maureen mu qin breakfast is the ...        3750   \n",
       "1  bak chor mee which translates to minced meat n...        2142   \n",
       "2  hokkien prawn mee is an iconic singapore dish ...        2918   \n",
       "3  if youre from nu youve probably treated yourse...         582   \n",
       "4  the newly opened hawkerman a soontobe halal ce...         527   \n",
       "\n",
       "                            tokenised_with_stopwords  \n",
       "0  [image, text, by, maureen, mu, qin, breakfast,...  \n",
       "1  [bak, chor, mee, which, translates, to, minced...  \n",
       "2  [hokkien, prawn, mee, is, an, iconic, singapor...  \n",
       "3  [if, you, re, from, nu, you, ve, probably, tre...  \n",
       "4  [the, newly, opened, hawkerman, a, soontobe, h...  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2110"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('combined_blogs.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
